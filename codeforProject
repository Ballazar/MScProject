{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9081357,"sourceType":"datasetVersion","datasetId":5479007},{"sourceId":9122316,"sourceType":"datasetVersion","datasetId":5506870},{"sourceId":90642,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":75987,"modelId":100696}],"dockerImageVersionId":30748,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nfrom sklearn.utils import resample\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import Sequence\nfrom multiprocessing import Pool\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T07:00:06.850079Z","iopub.execute_input":"2024-08-20T07:00:06.851059Z","iopub.status.idle":"2024-08-20T07:00:06.892044Z","shell.execute_reply.started":"2024-08-20T07:00:06.851023Z","shell.execute_reply":"2024-08-20T07:00:06.891144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = pd.read_csv(\"/kaggle/input/metadata/metadata_with_ITA.csv\")\nprint(metadata.columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:43:25.348299Z","iopub.execute_input":"2024-08-14T05:43:25.348733Z","iopub.status.idle":"2024-08-14T05:43:25.596922Z","shell.execute_reply.started":"2024-08-14T05:43:25.348697Z","shell.execute_reply":"2024-08-14T05:43:25.595694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_clean = metadata[['isic_id', 'benign_malignant']]\nprint(metadata_clean.isna().value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:11:47.835550Z","iopub.execute_input":"2024-08-14T06:11:47.836080Z","iopub.status.idle":"2024-08-14T06:11:47.918633Z","shell.execute_reply.started":"2024-08-14T06:11:47.836042Z","shell.execute_reply":"2024-08-14T06:11:47.917364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metadata_clean.describe())","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:12:18.612891Z","iopub.execute_input":"2024-08-14T06:12:18.613335Z","iopub.status.idle":"2024-08-14T06:12:18.668275Z","shell.execute_reply.started":"2024-08-14T06:12:18.613301Z","shell.execute_reply":"2024-08-14T06:12:18.667153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(args):\n    row, image_folder, output_folder, datagen, num_augmented = args\n    image_name = row['isic_id']\n    image_path = os.path.join(image_folder, image_name + '.jpg')\n    image = cv2.imread(image_path)\n    augmented_images = []\n    if image is not None:\n        image = np.expand_dims(image, axis=0)  # Add batch dimension\n        # Generate augmented images\n        aug_iter = datagen.flow(image, batch_size=1)\n        for i in range(num_augmented):\n            aug_image = next(aug_iter)[0].astype(np.uint8)  # Remove batch dimension\n            aug_image_name = f\"{image_name}_aug_{i}\"\n            aug_image_path = os.path.join(output_folder, aug_image_name + '.jpg')\n            cv2.imwrite(aug_image_path, aug_image)\n            # Create new metadata entry\n            new_row = row.copy()\n            new_row['isic_id'] = aug_image_name\n            augmented_images.append(new_row)\n    else:\n        print(f\"Image not found: {image_path}\")\n    return augmented_images\n\n# Function to augment and save images using multiprocessing\ndef augment_and_save_images_parallel(metadata, image_folder, output_folder, datagen, num_workers=4):\n    args_list = []\n    for idx, row in metadata.iterrows():\n        skin_tone = row['Skin_Tone']\n        if skin_tone == 'Tan':\n            num_augmented = 10\n        elif skin_tone == 'Intermediate':\n            num_augmented = 2\n        elif skin_tone == \"Brown\":\n            num_augmented = 30\n        else:\n            num_augmented = 0\n        if num_augmented > 0:\n            args_list.append((row, image_folder, output_folder, datagen, num_augmented))\n\n    augmented_metadata_entries = []\n    with Pool(num_workers) as pool:\n        for result in tqdm(pool.imap(augment_image, args_list), total=len(args_list)):\n            augmented_metadata_entries.extend(result)\n    return augmented_metadata_entries\n\n# Example usage\nmetadata_path = \"/kaggle/input/metadata/metadata_with_ITA.csv\"  \nimage_folder = \"/kaggle/input/clean-images1/processed_images1\"  \noutput_folder = \"/kaggle/working/augmented_images\"\n\n# Create output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Read the metadata\nmetadata = pd.read_csv(metadata_path)\n\n# Define the image data generator for augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Augment images using multiprocessing\naugmented_metadata_entries = augment_and_save_images_parallel(metadata, image_folder, output_folder, datagen, num_workers=4)\n\n# Save the new augmented metadata to a CSV file\naugmented_metadata = pd.DataFrame(augmented_metadata_entries)\ncombined_metadata = pd.concat([metadata, augmented_metadata])\ncombined_metadata.to_csv('/kaggle/working/combined_metadata_with_augmentation.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:16:10.342607Z","iopub.execute_input":"2024-08-11T09:16:10.343300Z","iopub.status.idle":"2024-08-11T09:21:46.759541Z","shell.execute_reply.started":"2024-08-11T09:16:10.343268Z","shell.execute_reply":"2024-08-11T09:21:46.758423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Paths to the original and augmented image folders\noriginal_image_folder = \"/kaggle/input/clean-images1/processed_images1\"  # Original images\naugmented_image_folder = \"/kaggle/working/augmented_images\"  # Augmented images\ncombined_image_folder = \"/kaggle/working/combined_images\"  # Path to save combined images\n\n# Create the combined image folder if it doesn't exist\nif not os.path.exists(combined_image_folder):\n    os.makedirs(combined_image_folder)\n\n# Function to copy images from source to destination\ndef copy_images(src_folder, dest_folder):\n    for filename in os.listdir(src_folder):\n        src_path = os.path.join(src_folder, filename)\n        dest_path = os.path.join(dest_folder, filename)\n        if os.path.isfile(src_path):\n            # Check if the file already exists in the destination folder\n            if not os.path.exists(dest_path):\n                shutil.copy2(src_path, dest_path)\n            else:\n                print(f\"File {filename} already exists in the destination folder.\")\n\n# Copy original images to the combined folder\ncopy_images(original_image_folder, combined_image_folder)\n\n# Copy augmented images to the combined folder\ncopy_images(augmented_image_folder, combined_image_folder)\n\nprint(\"Combining of image folders is complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:21:53.271940Z","iopub.execute_input":"2024-08-11T09:21:53.272328Z","iopub.status.idle":"2024-08-11T09:23:42.050572Z","shell.execute_reply.started":"2024-08-11T09:21:53.272296Z","shell.execute_reply":"2024-08-11T09:23:42.049577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths\nmetadata_aug_path = \"/kaggle/working/combined_metadata_with_augmentation.csv\"\n# Load metadata\nmetadata1 = pd.read_csv(metadata_aug_path)\n# Add .jpg extension to isic_id column\nmetadata1['isic_id'] = metadata1['isic_id'].apply(lambda x: x if x.endswith('.jpg') else f\"{x}.jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:00:30.009603Z","iopub.execute_input":"2024-08-20T07:00:30.009987Z","iopub.status.idle":"2024-08-20T07:00:30.623735Z","shell.execute_reply.started":"2024-08-20T07:00:30.009957Z","shell.execute_reply":"2024-08-20T07:00:30.622631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define colors that represent different skin tones\nskin_tone_colors = {\n    'Very Light': \"#f3d4b1\",  # Very light\n    'Light': \"#e6c29b\",       # Light\n    'Intermediate': \"#d4a981\",# Intermediate\n    'Tan': \"#b17c56\",         # Tan\n    'Brown': \"#8c512e\"        # Brown\n}\n\n# Define the order of skin tones from lightest to darkest\nskin_tone_order = ['Very Light', 'Light', 'Intermediate', 'Tan', 'Brown']\n\n# Function to sort value counts by predefined order\ndef sort_by_skin_tone_order(value_counts, order):\n    return value_counts.reindex(order).fillna(0)\n\n# Plotting the distribution of skin tones\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# ITA dataset\nita_skin_tone_counts = metadata['Skin_Tone'].value_counts()\nita_skin_tone_counts = sort_by_skin_tone_order(ita_skin_tone_counts, skin_tone_order)\naxes[0].bar(ita_skin_tone_counts.index, ita_skin_tone_counts.values, color=[skin_tone_colors[i] for i in ita_skin_tone_counts.index])\naxes[0].set_title('Skin Tone Distribution in ITA Dataset', fontsize=26)\naxes[0].set_xlabel('Skin Tone')\naxes[0].set_ylabel('Count')\n\n# Augmented dataset\naugmented_skin_tone_counts = metadata1['Skin_Tone'].value_counts()\naugmented_skin_tone_counts = sort_by_skin_tone_order(augmented_skin_tone_counts, skin_tone_order)\naxes[1].bar(augmented_skin_tone_counts.index, augmented_skin_tone_counts.values, color=[skin_tone_colors[i] for i in augmented_skin_tone_counts.index])\naxes[1].set_title('Skin Tone Distribution in Augmented Dataset', fontsize=26)\naxes[1].set_xlabel('Skin Tone')\naxes[1].set_ylabel('Count')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:39:57.435959Z","iopub.execute_input":"2024-08-14T17:39:57.436462Z","iopub.status.idle":"2024-08-14T17:39:57.988599Z","shell.execute_reply.started":"2024-08-14T17:39:57.436428Z","shell.execute_reply":"2024-08-14T17:39:57.987219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom PIL import Image\noutput_folder = '/kaggle/working/combined_images'\n\n# Select one malignant and one benign image based on the metadata\nmalignant_image = metadata[metadata['benign_malignant'] == 'malignant'].sample(1)['isic_id'].values[0]\nbenign_image = metadata[metadata['benign_malignant'] == 'benign'].sample(1)['isic_id'].values[0]\n\n# Define the full paths to the selected images\nmalignant_image_path = os.path.join(output_folder, malignant_image + '.jpg')\nbenign_image_path = os.path.join(output_folder, benign_image + '.jpg')\n\n# Load the images\nmalignant_img = Image.open(malignant_image_path)\nbenign_img = Image.open(benign_image_path)\n\n# Create a plot to display the images\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n# Display the malignant image\naxes[0].imshow(malignant_img)\naxes[0].set_title('Malignant')\naxes[0].axis('off')  # Hide axes\n\n# Display the benign image\naxes[1].imshow(benign_img)\naxes[1].set_title('Benign')\naxes[1].axis('off')  # Hide axes\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:42:40.252591Z","iopub.execute_input":"2024-08-14T17:42:40.253054Z","iopub.status.idle":"2024-08-14T17:42:40.909534Z","shell.execute_reply.started":"2024-08-14T17:42:40.253014Z","shell.execute_reply":"2024-08-14T17:42:40.908247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_folder = '/kaggle/working/combined_images'\n\n# Split into train and validation sets using train_test_split\ntrain_metadata, val_metadata = train_test_split(metadata1,\n                                                test_size=0.2,\n                                                random_state=42,\n                                                stratify=metadata1[['benign_malignant', 'Skin_Tone']])\n\n\n# Image data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Data generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_metadata,\n    directory=output_folder,\n    x_col='isic_id',\n    y_col='benign_malignant',\n    class_mode='binary',\n    target_size=(256, 256),\n    batch_size=64,\n    shuffle=True\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_metadata,\n    directory=output_folder,\n    x_col='isic_id',\n    y_col='benign_malignant',\n    class_mode='binary',\n    target_size=(256, 256),\n    batch_size=64,\n    shuffle=False\n)\n\n# Load pre-trained EfficientNetB3 model\nbase_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers[-20:]:\n    layer.trainable = True\n\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.precision_metric = tf.keras.metrics.Precision()\n        self.recall_metric = tf.keras.metrics.Recall()\n        \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.precision_metric.update_state(y_true, y_pred)\n        self.recall_metric.update_state(y_true, y_pred)\n        \n    def result(self):\n        precision = self.precision_metric.result()\n        recall = self.recall_metric.result()\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n    \n    def reset_states(self):\n        self.precision_metric.reset_states()\n        self.recall_metric.reset_states()\n\nnum_epochs = 30\n\n# Initialize a dictionary to store metrics for each skin tone\nskin_tones = val_metadata['Skin_Tone'].unique()\n\nmetrics_by_skin_tone_and_epoch = {tone: {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'roc_auc': []} for tone in skin_tones}\nmetrics_by_skin_tone_and_epoch['epoch'] = list(range(1, num_epochs + 1))\n\nclass MetricsBySkinTone(Callback):\n    def __init__(self, val_generator, val_metadata, skin_tones):\n        super().__init__()\n        self.val_generator = val_generator\n        self.val_metadata = val_metadata\n        self.skin_tones = skin_tones\n        self.epoch_metrics = {tone: {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'roc_auc': []} for tone in skin_tones}\n        self.epoch_metrics['epoch'] = []\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_predictions = self.model.predict(self.val_generator)\n        val_predictions = val_predictions.reshape(-1)\n        \n        # Map 'benign' and 'malignant' to 0 and 1 in the true labels\n        label_mapping = {'benign': 0, 'malignant': 1}\n        true_labels = self.val_metadata['benign_malignant'].map(label_mapping).values\n\n        val_results = pd.DataFrame({\n            'true_labels': true_labels,\n            'predictions': val_predictions,\n            'skin_tone': self.val_metadata['Skin_Tone'].values\n        })\n        \n        for skin_tone in self.skin_tones:\n            subset = val_results[val_results['skin_tone'] == skin_tone]\n            true_labels = subset['true_labels']\n            predictions = subset['predictions']\n            binary_predictions = (predictions > 0.5).astype(int)\n\n            if len(set(true_labels)) > 1:\n                accuracy = np.mean(binary_predictions == true_labels)\n                precision = precision_score(true_labels, binary_predictions, zero_division=0)\n                recall = recall_score(true_labels, binary_predictions, zero_division=0)\n                f1 = f1_score(true_labels, binary_predictions, zero_division=0)\n                fpr, tpr, _ = roc_curve(true_labels, predictions)\n                roc_auc = auc(fpr, tpr)\n            else:\n                accuracy = precision = recall = f1 = roc_auc = None\n\n            self.epoch_metrics[skin_tone]['accuracy'].append(accuracy)\n            self.epoch_metrics[skin_tone]['precision'].append(precision)\n            self.epoch_metrics[skin_tone]['recall'].append(recall)\n            self.epoch_metrics[skin_tone]['f1_score'].append(f1)\n            self.epoch_metrics[skin_tone]['roc_auc'].append(roc_auc)\n\n        self.epoch_metrics['epoch'].append(epoch)\n\nmetrics_callback = MetricsBySkinTone(val_generator, val_metadata, skin_tones)\n\n# Compute class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_metadata['benign_malignant']),\n    y=train_metadata['benign_malignant']\n)\n\nclass_weight_dict = dict(enumerate(class_weights))\n\n        \n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), F1Score()])\n\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    epochs=num_epochs,\n    validation_data=val_generator,\n    class_weight=class_weight_dict,\n    callbacks=[metrics_callback]\n)\n\n# Save the entire model to a HDF5 file\nmodel.save('/kaggle/working/efficientnetb3_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T07:00:34.168657Z","iopub.execute_input":"2024-08-20T07:00:34.169007Z","iopub.status.idle":"2024-08-20T13:05:23.224432Z","shell.execute_reply.started":"2024-08-20T07:00:34.168980Z","shell.execute_reply":"2024-08-20T13:05:23.223302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to visualize one image and its augmentations\ndef visualize_augmentation(generator, num_augmentations=4):\n    for X_batch, y_batch in generator:\n        # Select the first image in the batch\n        original_image = X_batch[0]\n        label = y_batch[0]\n        \n        # Generate augmentations of the selected image\n        augmentations = [original_image]\n        for _ in range(num_augmentations):\n            augmented_image = generator.datagen.random_transform(original_image)\n            augmentations.append(augmented_image)\n        \n        # Plot the original and augmented images\n        fig, axes = plt.subplots(1, num_augmentations + 1, figsize=(15, 5))\n        for i, ax in enumerate(axes):\n            ax.imshow(augmentations[i])\n            ax.set_title(f\"Augmentation {i}\" if i > 0 else f\"Original\")\n            ax.axis('off')\n        plt.show()\n        break  # We only need to visualize one batch\n\n# Visualize augmentations from the training generator\nvisualize_augmentation(train_generator)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T15:33:01.552434Z","iopub.execute_input":"2024-08-11T15:33:01.553163Z","iopub.status.idle":"2024-08-11T15:33:01.599466Z","shell.execute_reply.started":"2024-08-11T15:33:01.553132Z","shell.execute_reply":"2024-08-11T15:33:01.598211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils import resample\n\ndef bootstrap_roc(true_labels, predictions, num_bootstraps=1000, alpha=0.95):\n    bootstrapped_aucs = []\n    for _ in range(num_bootstraps):\n        # Resample with replacement\n        indices = resample(np.arange(len(predictions)))\n        if len(np.unique(true_labels.iloc[indices])) < 2:\n            # Skip this resample if we don't have both classes present\n            continue\n        fpr, tpr, _ = roc_curve(true_labels.iloc[indices], predictions.iloc[indices])\n        roc_auc = auc(fpr, tpr)\n        bootstrapped_aucs.append(roc_auc)\n\n    sorted_aucs = np.sort(bootstrapped_aucs)\n    lower_bound = np.percentile(sorted_aucs, (1 - alpha) / 2 * 100)\n    upper_bound = np.percentile(sorted_aucs, (1 + alpha) / 2 * 100)\n    return lower_bound, upper_bound\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:36:16.539589Z","iopub.execute_input":"2024-08-20T13:36:16.539971Z","iopub.status.idle":"2024-08-20T13:36:16.549141Z","shell.execute_reply.started":"2024-08-20T13:36:16.539939Z","shell.execute_reply":"2024-08-20T13:36:16.547854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef plot_roc_and_confusion_matrices(metrics_callback):\n    skin_tones = metrics_callback.skin_tones\n    val_predictions = model.predict(val_generator).reshape(-1)\n    label_mapping = {'benign': 0, 'malignant': 1}\n    true_labels = val_metadata['benign_malignant'].map(label_mapping).values\n\n    val_results = pd.DataFrame({\n        'true_labels': true_labels,\n        'predictions': val_predictions,\n        'skin_tone': val_metadata['Skin_Tone'].values\n    })\n\n    num_skin_tones = len(skin_tones)\n    fig, axes = plt.subplots(num_skin_tones, 2, figsize=(15, 5 * num_skin_tones))\n    \n    if num_skin_tones == 1:\n        axes = [axes]\n    \n    for i, skin_tone in enumerate(skin_tones):\n        subset = val_results[val_results['skin_tone'] == skin_tone]\n        true_labels = subset['true_labels']\n        predictions = subset['predictions']\n        binary_predictions = (predictions > 0.5).astype(int)\n\n        # ROC Curve\n        if len(set(true_labels)) > 1:\n            fpr, tpr, _ = roc_curve(true_labels, predictions)\n            roc_auc = auc(fpr, tpr)\n            lower_bound, upper_bound = bootstrap_roc(true_labels, predictions)\n            \n            axes[i][0].plot(fpr, tpr, label=f'{skin_tone} (AUC = {roc_auc:.2f})')\n            axes[i][0].fill_between(fpr, tpr - (roc_auc - lower_bound), tpr + (upper_bound - roc_auc), color='gray', alpha=0.2)\n        else:\n            axes[i][0].plot([0, 1], [0, 1], color='navy', linestyle='--', label=f'{skin_tone} (AUC = N/A)')\n        \n        axes[i][0].set_title(f'ROC Curve for {skin_tone}')\n        axes[i][0].set_xlabel('False Positive Rate')\n        axes[i][0].set_ylabel('True Positive Rate')\n        axes[i][0].legend(loc='lower right')\n        axes[i][0].grid(True)\n\n        # Confusion Matrix\n        cm = confusion_matrix(true_labels, binary_predictions)\n        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', ax=axes[i][1])\n        axes[i][1].set_title(f'Confusion Matrix for {skin_tone}')\n        axes[i][1].set_xlabel('Predicted Labels')\n        axes[i][1].set_ylabel('True Labels')\n\n    plt.tight_layout()\n    plt.show()\n\nplot_roc_and_confusion_matrices(metrics_callback)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:36:24.279739Z","iopub.execute_input":"2024-08-20T13:36:24.280479Z","iopub.status.idle":"2024-08-20T13:37:22.548065Z","shell.execute_reply.started":"2024-08-20T13:36:24.280436Z","shell.execute_reply":"2024-08-20T13:37:22.547045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_balanced_accuracy_ordered(metrics_callback):\n    # Define the order of skin tones from lightest to darkest\n    skin_tone_order = ['Light', 'Intermediate', 'Tan', 'Brown']  # Adjust this list according to your dataset\n\n    skin_tones = metrics_callback.skin_tones\n    val_predictions = model.predict(val_generator).reshape(-1)\n    label_mapping = {'benign': 0, 'malignant': 1}\n    true_labels = val_metadata['benign_malignant'].map(label_mapping).values\n\n    val_results = pd.DataFrame({\n        'true_labels': true_labels,\n        'predictions': val_predictions,\n        'skin_tone': val_metadata['Skin_Tone'].values\n    })\n\n    balanced_accuracies = {}\n\n    for skin_tone in skin_tones:\n        subset = val_results[val_results['skin_tone'] == skin_tone]\n        true_labels = subset['true_labels']\n        predictions = subset['predictions']\n        \n        # Calculate Balanced Accuracy\n        bal_acc = calculate_balanced_accuracy(true_labels, predictions)\n        balanced_accuracies[skin_tone] = bal_acc\n\n    # Sort the skin tones according to the predefined order\n    ordered_balanced_accuracies = {tone: balanced_accuracies[tone] for tone in skin_tone_order if tone in balanced_accuracies}\n\n    # Plotting the balanced accuracies\n    plt.figure(figsize=(10, 6))\n    plt.bar(ordered_balanced_accuracies.keys(), ordered_balanced_accuracies.values(), color='skyblue')\n    plt.xlabel('Skin Tone')\n    plt.ylabel('Balanced Accuracy')\n    plt.title('Balanced Accuracy by Skin Tone (Ordered)')\n    plt.ylim(0, 1)\n    plt.show()\n\n# Call the updated function\nplot_balanced_accuracy_ordered(metrics_callback)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:34:41.361400Z","iopub.execute_input":"2024-08-20T14:34:41.362272Z","iopub.status.idle":"2024-08-20T14:34:41.412772Z","shell.execute_reply.started":"2024-08-20T14:34:41.362234Z","shell.execute_reply":"2024-08-20T14:34:41.411593Z"},"trusted":true},"execution_count":null,"outputs":[]}]}